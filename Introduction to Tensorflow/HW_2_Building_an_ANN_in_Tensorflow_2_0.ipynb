{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW 2.Building an ANN in Tensorflow 2.0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiyushD17/PiyushD17.github.io/blob/master/Introduction%20to%20Tensorflow/HW_2_Building_an_ANN_in_Tensorflow_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZqLFmbCohs2",
        "colab_type": "text"
      },
      "source": [
        "## We will work with Fashion MNIST\n",
        "* Consists of 70,000 images of size 28 * 28 (784 pixels) with 10 different clothing categories.\n",
        "* 60,000 images for training and 10,000 for testing\n",
        "* We will build an ANN to classify these categories.\n",
        "* As we are not using a CNN yet, we will reshape our 28 * 28 sized images to 784*1 shape\n",
        "* For an ANN, the input layer is just a 1-D vector of certain numbers (like 784 * 1 elements).\n",
        "* Each pixel takes values from 0 to 255.\n",
        "* All images are black and white."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O187Vu6Fo7zu",
        "colab_type": "text"
      },
      "source": [
        "## Installing dependencies and setting up a GPU environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_meh5NKxo5vr",
        "colab_type": "code",
        "outputId": "6c010774-6ae8-4f00-a82a-aa50bb1d6e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0.alpha0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0.alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 58kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.3.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.16.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.33.6)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0.alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 32.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.1.7)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0.alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha0) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (0.16.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99IOAcZqqyW6",
        "colab_type": "text"
      },
      "source": [
        "We will use the Fashion MNIST dataset that comes with the tensorlfow library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1J2xQYRql4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zRpuyyorKSc",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing\n",
        "* Loading the dataset\n",
        "* Normalizing the images\n",
        "* Reshaping the dataset (1-D format, 784 * 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cf3L1YorN3g",
        "colab_type": "text"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwvmebETrGFK",
        "colab_type": "code",
        "outputId": "35186712-1b02-4741-86a4-666b2c24da7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "(X_train,y_train), (X_test,y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1uOBF2IrsBr",
        "colab_type": "text"
      },
      "source": [
        "* X_train contains 60,000 images (all black and white).\n",
        "* y_train contains 60,000 labels for the images in X_train.\n",
        "* X_test contains 10,000 images (all black and white).\n",
        "* y_test contains 10,000 labels for the images in X_test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKtg2cl4sJ0Z",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the images\n",
        "* We divide each of the image in the traiing and test sets by the maximum value a pixel can take (255).\n",
        "* In this way each pixel will be in the range [0,1]. By normalizing images we make sure that our model trains faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW0-AbaDrqKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-NpZipoICYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = X_test/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOaTyJsIIH4l",
        "colab_type": "text"
      },
      "source": [
        "## Reshaping the dataset\n",
        "* Since we are building a fully connected network, we reshape the training set and the test set into the vector format, i.e. 1 * 784."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7cwpyCoIEhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since each image's dimension is 28*28, we reshape the full dataset to [-1 (all elements), height*width]\n",
        "# -1 to consider all the images in the dataset. We maintain the first dimension (60000 for training or 10000 for test).\n",
        "X_train = X_train.reshape(-1,28*28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Eb49N3jIstN",
        "colab_type": "code",
        "outputId": "9b5ab44a-594c-4e6d-93e1-3e6e56673051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RWCWXs_Itou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Similarly reshaping the X_test\n",
        "X_test = X_test.reshape(-1,28*28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIX7pAtoI1OK",
        "colab_type": "code",
        "outputId": "ae3faf0c-5d13-420d-babb-7fc2c4218547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF4DhZeXKcBW",
        "colab_type": "text"
      },
      "source": [
        "## Building an Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXOha0NwKhaD",
        "colab_type": "text"
      },
      "source": [
        "### Defining the model\n",
        "* Simply define an object of the Sequential model.\n",
        "* We are building a fully connected neural network which is a series of dense layers and as opposed to being a computational graph it is a sequence of layers and hence we use the Sequential class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n58ZZJI3I35i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7NbUALhLWni",
        "colab_type": "text"
      },
      "source": [
        "### Adding a first fully-connected hidden layer\n",
        "* Layer hyper-parameters\n",
        "  * number of neurons/units = 128\n",
        "  * activation function : ReLU to break the linearity and help the NN learn non-linear relationships\n",
        "  * input shape = (784,) it is coming from the input layer and we have 784 neurons in the input layer, hence input shape = (784,)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dywF-AILVTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units = 128, activation = 'relu', input_shape=(784,)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiflJPLpMDoW",
        "colab_type": "text"
      },
      "source": [
        "### Adding a second layer with Dropout.\n",
        "Dropout is a Regularization technique where we randomly set neurons in a layer to zero (or deactivate them). That way while training those neurons won't be updated. As some percentage of neurons won't be updated the whole training process is long and we have less chance of __overfitting__. Usualyy we choose 20 to 50% (in this case 20%)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze24VumnMCl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxY0trchonQB",
        "colab_type": "text"
      },
      "source": [
        "### Adding a second fully-connected hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpPEMeSEn_ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qisTrtukotEA",
        "colab_type": "text"
      },
      "source": [
        "### Adding a Dropout layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZtOzRAeoU2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WePiwJH6oxo1",
        "colab_type": "text"
      },
      "source": [
        "### Adding a third fully-connected hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYkt3lOdoRVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPMg9REYRcVW",
        "colab_type": "text"
      },
      "source": [
        "## Adding the output layer\n",
        "  * units: number of classes in your dataset (10 in Fashion MNIST)\n",
        "  * activation = softmax in order to get probabilities for each class and the input image will be assigned to that category for which we get the highest probability.\n",
        "  * Once we define the input shape for the first hidden layer, we never need to define it in the proceeding layers because the model will understand by itself according to the connections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNaxYMoSOeW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units = 10, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnPobKmySZKc",
        "colab_type": "text"
      },
      "source": [
        "## Compiling the model\n",
        "  * Optimizer = Adam (to update the weights using SGD in backpropagation). Other option is __RMSProp__.\n",
        "  * Loss: Sparse softmax (categorical) crossentropy \n",
        "  * metrics: sparse categorical accuarcy (used when there are more than 2 classes)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dik-ELcaSWUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['sparse_categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pR70KdnTegm",
        "colab_type": "code",
        "outputId": "edd7fadc-1590-474d-8b24-3f1cc91399a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 111,146\n",
            "Trainable params: 111,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhg-lLvtgihk",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgdH6hUuThJE",
        "colab_type": "code",
        "outputId": "47d3068b-eea5-4af1-91a7-1e463a3c8451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# batch size is an optional argument\n",
        "model.fit(X_train, y_train,epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.5992 - sparse_categorical_accuracy: 0.7830\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.4364 - sparse_categorical_accuracy: 0.8411\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.4014 - sparse_categorical_accuracy: 0.8529\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.3791 - sparse_categorical_accuracy: 0.8627\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.3653 - sparse_categorical_accuracy: 0.8663\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.3504 - sparse_categorical_accuracy: 0.8727\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3412 - sparse_categorical_accuracy: 0.8754\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3316 - sparse_categorical_accuracy: 0.8787\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.3236 - sparse_categorical_accuracy: 0.8819\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.3183 - sparse_categorical_accuracy: 0.8840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1e8e95e5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prUVSjLVhSss",
        "colab_type": "text"
      },
      "source": [
        "## Model evaluation and prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfWTVo0sg1vA",
        "colab_type": "code",
        "outputId": "7fb25dc4-15bb-4832-9a91-44b85be75bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 52us/sample - loss: 0.3296 - sparse_categorical_accuracy: 0.8806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSdZST2vhc55",
        "colab_type": "code",
        "outputId": "93023ca2-d3a8-4c4d-b95c-b837f2a1a9ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-qL34hrhekJ",
        "colab_type": "code",
        "outputId": "fa5ddb89-92ec-4fb9-e141-8435b723fb4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32958651356697083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-FDHGKvjZfU",
        "colab_type": "code",
        "outputId": "3369d9bd-af74-4b5b-eff9-5ea48b9d472e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8805999755859375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qto0oRYgjQTb",
        "colab_type": "text"
      },
      "source": [
        "## Saving the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlkgS_Xxj4NU",
        "colab_type": "text"
      },
      "source": [
        "### Saving the architecture (topology) of the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs9L_n2UhiOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open('fashion_model.json','w') as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3e_DqbIkNnA",
        "colab_type": "text"
      },
      "source": [
        "### Saving Network Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjithSdlkLxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('fashion_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}